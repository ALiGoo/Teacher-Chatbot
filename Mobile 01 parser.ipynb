{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 爬取Mobile 01的機車遊記頁面"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 找到總共有幾頁"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "html = urlopen(\"https://www.mobile01.com/topiclist.php?f=416&p=1\")\n",
    "soup = BeautifulSoup(html,\"html\")\n",
    "pages = soup.find_all('div',{\"class\":\"pagination\"})\n",
    "pages = pages[1].find_all('a')\n",
    "pages = pages[-1].text\n",
    "pages = int(pages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 找到要的資料"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic = []\n",
    "Popularity = []\n",
    "reply_amount = []\n",
    "author = []\n",
    "issuing_time = []\n",
    "reply_name = []\n",
    "reply_time = []\n",
    "link = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for page in range (pages):\n",
    "    html = urlopen(\"https://www.mobile01.com/topiclist.php?f=416&p=\"+str(page+1))\n",
    "    soup = BeautifulSoup(html,\"html\")\n",
    "    data = soup.find('div',{\"class\":\"tablelist forumlist\"})\n",
    "    data = data.find_all('tr')\n",
    "    for point in data[1:]:\n",
    "        topic.append(point.find('span',{\"class\":\"subject-text\"}).text.split('»')[0])\n",
    "        Popularity.append(point.find('a').get('title').split(' ')[1])\n",
    "        reply_amount.append(point.find('td',{\"class\":\"reply\"}).text)\n",
    "        author.append(point.find_all('p')[1].text)\n",
    "        issuing_time.append(point.find_all('p')[0].text)\n",
    "        reply_name.append(point.find_all('p')[3].text)\n",
    "        reply_time.append(point.find_all('p')[2].text)\n",
    "        link.append('https://www.mobile01.com/'+point.find('a').get('href'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 存成CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "point_df = pd.DataFrame({\"主題\":topic,\"人氣\":Popularity,\"作者\":author,\n",
    "                         \"發文時間\":issuing_time,\"最新回應者\":reply_name,\n",
    "                         \"最新回應時間\":reply_time,\"回應人數\":reply_amount,\n",
    "                         \"連結\":link},columns = [\"主題\", \"人氣\", \"作者\",\"發文時間\",\n",
    "                                               \"最新回應者\",\"最新回應時間\",\"回應人數\",\n",
    "                                               \"連結\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "point_df.to_csv(\"travel.csv\", index=False,encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 機車遊記子板？似乎太少了,試試把整個機車板都爬下來"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import threading\n",
    "import time\n",
    "import queue\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 找到所有子版的網址"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "board_link = []\n",
    "\n",
    "html = urlopen(\"https://www.mobile01.com/forumlist.php?f=29\")\n",
    "soup = BeautifulSoup(html,\"lxml\")\n",
    "soup = soup.find('div',{\"class\":\"tablelist\"})\n",
    "soup = soup.find_all('td',{\"class\":\"forumname\"})\n",
    "for row in soup:\n",
    "    board_link.append('https://www.mobile01.com/' + row.find('a').get('href'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 找到總共有幾頁"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pages(link):\n",
    "    html = urlopen(link)\n",
    "    soup = BeautifulSoup(html,\"lxml\")\n",
    "    pages = soup.find_all('div',{\"class\":\"pagination\"})\n",
    "    pages = pages[1].find_all('a')\n",
    "    pages = pages[-1].text\n",
    "    pages = int(pages)\n",
    "    return pages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 把所有要爬的網頁網址建成Queue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "link_queue = queue.Queue()\n",
    "for board in board_link:\n",
    "    for page in range (get_pages(board)):\n",
    "        link_queue.put(board+'&p='+str(page+1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 找到要的資料"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(page_link):\n",
    "    topic = []\n",
    "    Popularity = []\n",
    "    reply_amount = []\n",
    "    author = []\n",
    "    issuing_time = []\n",
    "    reply_name = []\n",
    "    reply_time = []\n",
    "    link = []\n",
    "    \n",
    "    html = urlopen(page_link)\n",
    "    soup = BeautifulSoup(html,\"lxml\")\n",
    "    data = soup.find('div',{\"class\":\"tablelist forumlist\"})\n",
    "    data = data.find_all('tr')\n",
    "    for point in data[1:]:\n",
    "        topic.append(point.find('span',{\"class\":\"subject-text\"}).text.split('»')[0])\n",
    "        Popularity.append(point.find('a').get('title').split(' ')[1])\n",
    "        reply_amount.append(point.find('td',{\"class\":\"reply\"}).text)\n",
    "        author.append(point.find_all('p')[1].text)\n",
    "        issuing_time.append(point.find_all('p')[0].text)\n",
    "        reply_name.append(point.find_all('p')[3].text)\n",
    "        reply_time.append(point.find_all('p')[2].text)\n",
    "        link.append('https://www.mobile01.com/'+point.find('a').get('href'))\n",
    "        \n",
    "    return topic,Popularity,reply_amount,author,issuing_time,reply_name,reply_time,link"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 寫入CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_csv(topic,Popularity,reply_amount,author,issuing_time,reply_name,reply_time,link):\n",
    "    with open('bike.csv', 'a+', newline='') as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        for i in range (len(topic)):        \n",
    "            writer.writerow([topic[i],Popularity[i],reply_amount[i],author[i],issuing_time[i],\n",
    "                             reply_name[i],reply_time[i],link[i]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Thread建成class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Worker(threading.Thread):\n",
    "    def __init__(self, queue,lock):\n",
    "        threading.Thread.__init__(self)\n",
    "        self.queue = queue\n",
    "        self.lock = lock\n",
    "        \n",
    "    def run(self):\n",
    "        while self.queue.qsize() > 0:\n",
    "            link = self.queue.get()\n",
    "            topic,Popularity,reply_amount,author,issuing_time,reply_name,reply_time,link = get_data(link)\n",
    "            lock.acquire()\n",
    "            write_csv(topic,Popularity,reply_amount,author,issuing_time,reply_name,reply_time,link)\n",
    "            self.lock.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 生成Thread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "workers = []\n",
    "lock = threading.Lock()\n",
    "\n",
    "for i in range (1000):\n",
    "    workers.append(Worker(link_queue,lock))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 使用多執行緒爬取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for worker in workers:\n",
    "    worker.start()\n",
    "    time.sleep(1)\n",
    "for worker in workers:\n",
    "    worker.join()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python使用MultiThread似乎效率不彰,來試試MultiProcess吧"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import multiprocessing as mp\n",
    "import queue\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 找到所有子版的網址"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "board_link = []\n",
    "\n",
    "html = urlopen(\"https://www.mobile01.com/forumlist.php?f=29\")\n",
    "soup = BeautifulSoup(html,\"lxml\")\n",
    "soup = soup.find('div',{\"class\":\"tablelist\"})\n",
    "soup = soup.find_all('td',{\"class\":\"forumname\"})\n",
    "for row in soup:\n",
    "    board_link.append('https://www.mobile01.com/' + row.find('a').get('href'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 找到總共有幾頁"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pages(link):\n",
    "    html = urlopen(link)\n",
    "    soup = BeautifulSoup(html,\"lxml\")\n",
    "    pages = soup.find_all('div',{\"class\":\"pagination\"})\n",
    "    pages = pages[1].find_all('a')\n",
    "    pages = pages[-1].text\n",
    "    pages = int(pages)\n",
    "    return pages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 把所有要爬的網頁網址建成List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "link_list = []\n",
    "for board in board_link:\n",
    "    for page in range (get_pages(board)):\n",
    "        link_list.append(board+'&p='+str(page+1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 找到要的資料"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(page_link):\n",
    "    topic = []\n",
    "    Popularity = []\n",
    "    reply_amount = []\n",
    "    author = []\n",
    "    issuing_time = []\n",
    "    reply_name = []\n",
    "    reply_time = []\n",
    "    link = []\n",
    "    try:\n",
    "        html = urlopen(page_link)\n",
    "        soup = BeautifulSoup(html,\"lxml\")\n",
    "        data = soup.find('div',{\"class\":\"tablelist forumlist\"})\n",
    "        data = data.find_all('tr')\n",
    "        for point in data[1:]:\n",
    "            topic.append(point.find('span',{\"class\":\"subject-text\"}).text.split('»')[0])\n",
    "            Popularity.append(point.find('a').get('title').split(' ')[1])\n",
    "            reply_amount.append(point.find('td',{\"class\":\"reply\"}).text)\n",
    "            author.append(point.find_all('p')[1].text)\n",
    "            issuing_time.append(point.find_all('p')[0].text)\n",
    "            reply_name.append(point.find_all('p')[3].text)\n",
    "            reply_time.append(point.find_all('p')[2].text)\n",
    "            link.append('https://www.mobile01.com/'+point.find('a').get('href'))\n",
    "\n",
    "        return pd.DataFrame({\"主題\":topic,\"人氣\":Popularity,\"作者\":author,\n",
    "                             \"發文時間\":issuing_time,\"最新回應者\":reply_name,\n",
    "                             \"最新回應時間\":reply_time,\"回應人數\":reply_amount,\n",
    "                             \"連結\":link},columns = [\"主題\", \"人氣\", \"作者\",\"發文時間\",\n",
    "                                                   \"最新回應者\",\"最新回應時間\",\"回應人數\",\n",
    "                                                   \"連結\"])\n",
    "    except:\n",
    "        print('error')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 用MultiProcess的pool來爬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multicore(link_list):\n",
    "    pool = mp.Pool()\n",
    "    data = pool.map(get_data, link_list)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 看看速度如何吧"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "總花費時間為：6.624648344516754\n"
     ]
    }
   ],
   "source": [
    "st = time.time()\n",
    "data = multicore(link_list)\n",
    "st1 = time.time()\n",
    "print ('總花費時間為：' + str((st1-st)/60))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 生成CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[0].to_csv(\"bike.csv\", index=False,mode = 'w', encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in data[1:]:\n",
    "    row.to_csv(\"bike.csv\", index=False,mode = 'a+', header = False, encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-b8623cd74e78>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mnow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mbefore\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m60\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'1 second'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "before = time.time()\n",
    "\n",
    "while True:\n",
    "    now = time.time()\n",
    "    if ((now-before)/60) >= 1:\n",
    "        print ('1 second')\n",
    "    before = now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
